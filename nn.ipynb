{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "print(tips.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_bill</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.675734</td>\n",
       "      <td>0.144877</td>\n",
       "      <td>0.085721</td>\n",
       "      <td>-0.043550</td>\n",
       "      <td>-0.183118</td>\n",
       "      <td>0.598315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip</th>\n",
       "      <td>0.675734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088862</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>-0.011548</td>\n",
       "      <td>-0.121629</td>\n",
       "      <td>0.489299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.144877</td>\n",
       "      <td>0.088862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>-0.078292</td>\n",
       "      <td>-0.205231</td>\n",
       "      <td>0.086195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker</th>\n",
       "      <td>0.085721</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.282721</td>\n",
       "      <td>-0.054921</td>\n",
       "      <td>-0.133178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>-0.043550</td>\n",
       "      <td>-0.011548</td>\n",
       "      <td>-0.078292</td>\n",
       "      <td>-0.282721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638019</td>\n",
       "      <td>0.069510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>-0.183118</td>\n",
       "      <td>-0.121629</td>\n",
       "      <td>-0.205231</td>\n",
       "      <td>-0.054921</td>\n",
       "      <td>0.638019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.103411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>0.598315</td>\n",
       "      <td>0.489299</td>\n",
       "      <td>0.086195</td>\n",
       "      <td>-0.133178</td>\n",
       "      <td>0.069510</td>\n",
       "      <td>-0.103411</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_bill       tip       sex    smoker       day      time  \\\n",
       "total_bill    1.000000  0.675734  0.144877  0.085721 -0.043550 -0.183118   \n",
       "tip           0.675734  1.000000  0.088862  0.005929 -0.011548 -0.121629   \n",
       "sex           0.144877  0.088862  1.000000  0.002816 -0.078292 -0.205231   \n",
       "smoker        0.085721  0.005929  0.002816  1.000000 -0.282721 -0.054921   \n",
       "day          -0.043550 -0.011548 -0.078292 -0.282721  1.000000  0.638019   \n",
       "time         -0.183118 -0.121629 -0.205231 -0.054921  0.638019  1.000000   \n",
       "size          0.598315  0.489299  0.086195 -0.133178  0.069510 -0.103411   \n",
       "\n",
       "                size  \n",
       "total_bill  0.598315  \n",
       "tip         0.489299  \n",
       "sex         0.086195  \n",
       "smoker     -0.133178  \n",
       "day         0.069510  \n",
       "time       -0.103411  \n",
       "size        1.000000  "
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sex','smoker','day','time']\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in columns:\n",
    "    tips[col] = le.fit_transform(tips[col])\n",
    "tips.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((244, 6), (244,))"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tips['tip']\n",
    "X = tips.drop(['tip'], axis=1)\n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 6)"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X,y, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhagya/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, activation = 'relu', input_shape = (X_train.shape[1],)))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - loss: 14.2280 - mae: 3.0078 - mse: 14.2280 - val_loss: 5.2311 - val_mae: 1.6543 - val_mse: 5.2311\n",
      "Epoch 2/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 5.2210 - mae: 1.5285 - mse: 5.2210 - val_loss: 2.3424 - val_mae: 1.2152 - val_mse: 2.3424\n",
      "Epoch 3/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 3.1907 - mae: 1.1868 - mse: 3.1907 - val_loss: 1.9876 - val_mae: 1.1562 - val_mse: 1.9876\n",
      "Epoch 4/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - loss: 3.8519 - mae: 1.4697 - mse: 3.8519 - val_loss: 1.8711 - val_mae: 1.1013 - val_mse: 1.8711\n",
      "Epoch 5/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 3.2546 - mae: 1.3044 - mse: 3.2546 - val_loss: 1.7101 - val_mae: 1.0566 - val_mse: 1.7101\n",
      "Epoch 6/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 2.1907 - mae: 1.1016 - mse: 2.1907 - val_loss: 1.5645 - val_mae: 1.0137 - val_mse: 1.5645\n",
      "Epoch 7/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 2.4432 - mae: 1.1785 - mse: 2.4432 - val_loss: 1.4973 - val_mae: 0.9745 - val_mse: 1.4973\n",
      "Epoch 8/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 2.3284 - mae: 1.1748 - mse: 2.3284 - val_loss: 1.4395 - val_mae: 0.9434 - val_mse: 1.4395\n",
      "Epoch 9/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 1.9392 - mae: 1.0371 - mse: 1.9392 - val_loss: 1.3672 - val_mae: 0.9142 - val_mse: 1.3672\n",
      "Epoch 10/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - loss: 2.0720 - mae: 1.0290 - mse: 2.0720 - val_loss: 1.3132 - val_mae: 0.8906 - val_mse: 1.3132\n",
      "Epoch 11/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 2.0577 - mae: 1.0038 - mse: 2.0577 - val_loss: 1.2579 - val_mae: 0.8681 - val_mse: 1.2579\n",
      "Epoch 12/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 2.3200 - mae: 1.1042 - mse: 2.3200 - val_loss: 1.3003 - val_mae: 0.8853 - val_mse: 1.3003\n",
      "Epoch 13/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 2.4620 - mae: 1.1226 - mse: 2.4620 - val_loss: 1.2067 - val_mae: 0.8493 - val_mse: 1.2067\n",
      "Epoch 14/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 2.2192 - mae: 1.0770 - mse: 2.2192 - val_loss: 1.1379 - val_mae: 0.8188 - val_mse: 1.1379\n",
      "Epoch 15/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 2.1293 - mae: 1.1077 - mse: 2.1293 - val_loss: 1.1049 - val_mae: 0.8069 - val_mse: 1.1049\n",
      "Epoch 16/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 1.4867 - mae: 0.9522 - mse: 1.4867 - val_loss: 1.0609 - val_mae: 0.7823 - val_mse: 1.0609\n",
      "Epoch 17/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 1.3589 - mae: 0.8945 - mse: 1.3589 - val_loss: 1.0541 - val_mae: 0.7890 - val_mse: 1.0541\n",
      "Epoch 18/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 1.6319 - mae: 0.8720 - mse: 1.6319 - val_loss: 1.0626 - val_mae: 0.8020 - val_mse: 1.0626\n",
      "Epoch 19/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 1.7025 - mae: 0.9974 - mse: 1.7025 - val_loss: 1.0156 - val_mae: 0.7769 - val_mse: 1.0156\n",
      "Epoch 20/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 1.7028 - mae: 0.9819 - mse: 1.7028 - val_loss: 1.0145 - val_mae: 0.7825 - val_mse: 1.0145\n",
      "Epoch 21/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 1.8342 - mae: 1.0086 - mse: 1.8342 - val_loss: 0.9894 - val_mae: 0.7702 - val_mse: 0.9894\n",
      "Epoch 22/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 1.7763 - mae: 0.9784 - mse: 1.7763 - val_loss: 0.9848 - val_mae: 0.7710 - val_mse: 0.9848\n",
      "Epoch 23/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 1.6799 - mae: 0.9924 - mse: 1.6799 - val_loss: 0.9278 - val_mae: 0.7341 - val_mse: 0.9278\n",
      "Epoch 24/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 1.6752 - mae: 0.9337 - mse: 1.6752 - val_loss: 0.9852 - val_mae: 0.7755 - val_mse: 0.9852\n",
      "Epoch 25/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 1.9766 - mae: 1.0382 - mse: 1.9766 - val_loss: 0.9087 - val_mae: 0.7298 - val_mse: 0.9087\n",
      "Epoch 26/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.8669 - mae: 1.0109 - mse: 1.8669 - val_loss: 0.9783 - val_mae: 0.7730 - val_mse: 0.9783\n",
      "Epoch 27/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 1.8086 - mae: 0.9965 - mse: 1.8086 - val_loss: 0.9600 - val_mae: 0.7635 - val_mse: 0.9600\n",
      "Epoch 28/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4926 - mae: 0.9203 - mse: 1.4926 - val_loss: 0.8596 - val_mae: 0.7099 - val_mse: 0.8596\n",
      "Epoch 29/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 1.5202 - mae: 0.9366 - mse: 1.5202 - val_loss: 0.8535 - val_mae: 0.7091 - val_mse: 0.8535\n",
      "Epoch 30/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 1.3902 - mae: 0.8736 - mse: 1.3902 - val_loss: 0.8487 - val_mae: 0.7080 - val_mse: 0.8487\n",
      "Epoch 31/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.2660 - mae: 0.8258 - mse: 1.2660 - val_loss: 0.9272 - val_mae: 0.7483 - val_mse: 0.9272\n",
      "Epoch 32/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 1.3435 - mae: 0.8841 - mse: 1.3435 - val_loss: 0.8741 - val_mae: 0.7187 - val_mse: 0.8741\n",
      "Epoch 33/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 1.6305 - mae: 0.9696 - mse: 1.6305 - val_loss: 0.8831 - val_mae: 0.7243 - val_mse: 0.8831\n",
      "Epoch 34/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.3952 - mae: 0.8872 - mse: 1.3952 - val_loss: 0.8788 - val_mae: 0.7227 - val_mse: 0.8788\n",
      "Epoch 35/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.4865 - mae: 0.9209 - mse: 1.4865 - val_loss: 0.8747 - val_mae: 0.7209 - val_mse: 0.8747\n",
      "Epoch 36/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 1.3037 - mae: 0.8626 - mse: 1.3037 - val_loss: 0.8428 - val_mae: 0.7033 - val_mse: 0.8428\n",
      "Epoch 37/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.5289 - mae: 0.9179 - mse: 1.5289 - val_loss: 0.8536 - val_mae: 0.7091 - val_mse: 0.8536\n",
      "Epoch 38/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.1325 - mae: 0.7778 - mse: 1.1325 - val_loss: 0.7960 - val_mae: 0.6920 - val_mse: 0.7960\n",
      "Epoch 39/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.4704 - mae: 0.8783 - mse: 1.4704 - val_loss: 0.7919 - val_mae: 0.6901 - val_mse: 0.7919\n",
      "Epoch 40/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 1.2225 - mae: 0.8599 - mse: 1.2225 - val_loss: 0.8595 - val_mae: 0.7125 - val_mse: 0.8595\n",
      "Epoch 41/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 1.1513 - mae: 0.7806 - mse: 1.1513 - val_loss: 0.8189 - val_mae: 0.6939 - val_mse: 0.8189\n",
      "Epoch 42/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 1.2819 - mae: 0.8468 - mse: 1.2819 - val_loss: 0.7939 - val_mae: 0.6854 - val_mse: 0.7939\n",
      "Epoch 43/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 1.3931 - mae: 0.8587 - mse: 1.3931 - val_loss: 0.8360 - val_mae: 0.7013 - val_mse: 0.8360\n",
      "Epoch 44/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 0.9373 - mae: 0.6860 - mse: 0.9373 - val_loss: 0.7776 - val_mae: 0.6832 - val_mse: 0.7776\n",
      "Epoch 45/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.0531 - mae: 0.7384 - mse: 1.0531 - val_loss: 0.8266 - val_mae: 0.6968 - val_mse: 0.8266\n",
      "Epoch 46/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 1.2004 - mae: 0.8183 - mse: 1.2004 - val_loss: 0.7609 - val_mae: 0.6815 - val_mse: 0.7609\n",
      "Epoch 47/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 1.5581 - mae: 0.9223 - mse: 1.5581 - val_loss: 0.7806 - val_mae: 0.6821 - val_mse: 0.7806\n",
      "Epoch 48/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 1.1088 - mae: 0.7619 - mse: 1.1088 - val_loss: 0.9187 - val_mae: 0.7414 - val_mse: 0.9187\n",
      "Epoch 49/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 1.3944 - mae: 0.9096 - mse: 1.3944 - val_loss: 0.7744 - val_mae: 0.6782 - val_mse: 0.7744\n",
      "Epoch 50/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 1.2835 - mae: 0.8214 - mse: 1.2835 - val_loss: 0.7477 - val_mae: 0.6753 - val_mse: 0.7477\n",
      "Epoch 51/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.3362 - mae: 0.8555 - mse: 1.3362 - val_loss: 0.7867 - val_mae: 0.6809 - val_mse: 0.7867\n",
      "Epoch 52/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - loss: 1.1387 - mae: 0.7571 - mse: 1.1387 - val_loss: 0.8052 - val_mae: 0.6867 - val_mse: 0.8052\n",
      "Epoch 53/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.6442 - mae: 0.9332 - mse: 1.6442 - val_loss: 0.7794 - val_mae: 0.6787 - val_mse: 0.7794\n",
      "Epoch 54/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 1.3025 - mae: 0.8220 - mse: 1.3025 - val_loss: 0.7392 - val_mae: 0.6721 - val_mse: 0.7392\n",
      "Epoch 55/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 1.4459 - mae: 0.8970 - mse: 1.4459 - val_loss: 0.7771 - val_mae: 0.6778 - val_mse: 0.7771\n",
      "Epoch 56/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.3189 - mae: 0.8834 - mse: 1.3189 - val_loss: 0.7851 - val_mae: 0.6802 - val_mse: 0.7851\n",
      "Epoch 57/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 0.9751 - mae: 0.7387 - mse: 0.9751 - val_loss: 0.8017 - val_mae: 0.6878 - val_mse: 0.8017\n",
      "Epoch 58/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.9945 - mae: 0.7390 - mse: 0.9945 - val_loss: 0.7708 - val_mae: 0.6749 - val_mse: 0.7708\n",
      "Epoch 59/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.1947 - mae: 0.8279 - mse: 1.1947 - val_loss: 0.7988 - val_mae: 0.6875 - val_mse: 0.7988\n",
      "Epoch 60/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 1.0479 - mae: 0.7449 - mse: 1.0479 - val_loss: 0.7271 - val_mae: 0.6678 - val_mse: 0.7271\n",
      "Epoch 61/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.1256 - mae: 0.7679 - mse: 1.1256 - val_loss: 0.7874 - val_mae: 0.6831 - val_mse: 0.7874\n",
      "Epoch 62/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 1.2486 - mae: 0.8253 - mse: 1.2486 - val_loss: 0.7630 - val_mae: 0.6726 - val_mse: 0.7630\n",
      "Epoch 63/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 1.5748 - mae: 0.9209 - mse: 1.5748 - val_loss: 0.7680 - val_mae: 0.6750 - val_mse: 0.7680\n",
      "Epoch 64/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.5274 - mae: 0.9321 - mse: 1.5274 - val_loss: 0.7229 - val_mae: 0.6666 - val_mse: 0.7229\n",
      "Epoch 65/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.3042 - mae: 0.8183 - mse: 1.3042 - val_loss: 0.7865 - val_mae: 0.6837 - val_mse: 0.7865\n",
      "Epoch 66/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 1.7088 - mae: 0.9760 - mse: 1.7088 - val_loss: 0.7514 - val_mae: 0.6680 - val_mse: 0.7514\n",
      "Epoch 67/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 1.4841 - mae: 0.8576 - mse: 1.4841 - val_loss: 0.7560 - val_mae: 0.6701 - val_mse: 0.7560\n",
      "Epoch 68/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 1.1992 - mae: 0.8179 - mse: 1.1992 - val_loss: 0.7201 - val_mae: 0.6595 - val_mse: 0.7201\n",
      "Epoch 69/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 1.0068 - mae: 0.7389 - mse: 1.0068 - val_loss: 0.7269 - val_mae: 0.6619 - val_mse: 0.7269\n",
      "Epoch 70/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.3161 - mae: 0.8271 - mse: 1.3161 - val_loss: 0.7203 - val_mae: 0.6587 - val_mse: 0.7203\n",
      "Epoch 71/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 1.2775 - mae: 0.8437 - mse: 1.2775 - val_loss: 0.7732 - val_mae: 0.6785 - val_mse: 0.7732\n",
      "Epoch 72/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.6683 - mae: 0.9449 - mse: 1.6683 - val_loss: 0.7166 - val_mae: 0.6579 - val_mse: 0.7166\n",
      "Epoch 73/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.3533 - mae: 0.8874 - mse: 1.3533 - val_loss: 0.7123 - val_mae: 0.6556 - val_mse: 0.7123\n",
      "Epoch 74/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.2994 - mae: 0.8253 - mse: 1.2994 - val_loss: 0.7112 - val_mae: 0.6556 - val_mse: 0.7112\n",
      "Epoch 75/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.2248 - mae: 0.8664 - mse: 1.2248 - val_loss: 0.7021 - val_mae: 0.6528 - val_mse: 0.7021\n",
      "Epoch 76/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.2605 - mae: 0.8498 - mse: 1.2605 - val_loss: 0.6984 - val_mae: 0.6507 - val_mse: 0.6984\n",
      "Epoch 77/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 1.2355 - mae: 0.8175 - mse: 1.2355 - val_loss: 0.6974 - val_mae: 0.6501 - val_mse: 0.6974\n",
      "Epoch 78/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 1.5292 - mae: 0.8941 - mse: 1.5292 - val_loss: 0.7084 - val_mae: 0.6555 - val_mse: 0.7084\n",
      "Epoch 79/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.2017 - mae: 0.8025 - mse: 1.2017 - val_loss: 0.7376 - val_mae: 0.6642 - val_mse: 0.7376\n",
      "Epoch 80/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.1920 - mae: 0.8159 - mse: 1.1920 - val_loss: 0.6895 - val_mae: 0.6467 - val_mse: 0.6895\n",
      "Epoch 81/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 1.2710 - mae: 0.8498 - mse: 1.2710 - val_loss: 0.6954 - val_mae: 0.6492 - val_mse: 0.6954\n",
      "Epoch 82/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 1.7537 - mae: 0.9884 - mse: 1.7537 - val_loss: 0.7490 - val_mae: 0.6690 - val_mse: 0.7490\n",
      "Epoch 83/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.1664 - mae: 0.7907 - mse: 1.1664 - val_loss: 0.7117 - val_mae: 0.6553 - val_mse: 0.7117\n",
      "Epoch 84/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 1.4970 - mae: 0.9119 - mse: 1.4970 - val_loss: 0.6994 - val_mae: 0.6502 - val_mse: 0.6994\n",
      "Epoch 85/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.0928 - mae: 0.7368 - mse: 1.0928 - val_loss: 0.7111 - val_mae: 0.6547 - val_mse: 0.7111\n",
      "Epoch 86/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.2273 - mae: 0.8458 - mse: 1.2273 - val_loss: 0.6952 - val_mae: 0.6518 - val_mse: 0.6952\n",
      "Epoch 87/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.1985 - mae: 0.8213 - mse: 1.1985 - val_loss: 0.6932 - val_mae: 0.6483 - val_mse: 0.6932\n",
      "Epoch 88/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 0.9730 - mae: 0.7203 - mse: 0.9730 - val_loss: 0.6871 - val_mae: 0.6460 - val_mse: 0.6871\n",
      "Epoch 89/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.4590 - mae: 0.8941 - mse: 1.4590 - val_loss: 0.6865 - val_mae: 0.6476 - val_mse: 0.6865\n",
      "Epoch 90/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.2948 - mae: 0.8583 - mse: 1.2948 - val_loss: 0.7203 - val_mae: 0.6579 - val_mse: 0.7203\n",
      "Epoch 91/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.1298 - mae: 0.7610 - mse: 1.1298 - val_loss: 0.7133 - val_mae: 0.6542 - val_mse: 0.7133\n",
      "Epoch 92/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.0941 - mae: 0.7978 - mse: 1.0941 - val_loss: 0.7448 - val_mae: 0.6690 - val_mse: 0.7448\n",
      "Epoch 93/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 1.3048 - mae: 0.8543 - mse: 1.3048 - val_loss: 0.6999 - val_mae: 0.6502 - val_mse: 0.6999\n",
      "Epoch 94/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.1636 - mae: 0.7879 - mse: 1.1636 - val_loss: 0.7613 - val_mae: 0.6743 - val_mse: 0.7613\n",
      "Epoch 95/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 1.2079 - mae: 0.7938 - mse: 1.2079 - val_loss: 0.7444 - val_mae: 0.6680 - val_mse: 0.7444\n",
      "Epoch 96/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 1.7225 - mae: 1.0147 - mse: 1.7225 - val_loss: 0.7005 - val_mae: 0.6509 - val_mse: 0.7005\n",
      "Epoch 97/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.4307 - mae: 0.8810 - mse: 1.4307 - val_loss: 0.7064 - val_mae: 0.6529 - val_mse: 0.7064\n",
      "Epoch 98/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 0.9872 - mae: 0.7460 - mse: 0.9872 - val_loss: 0.7072 - val_mae: 0.6522 - val_mse: 0.7072\n",
      "Epoch 99/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.6966 - mae: 0.9437 - mse: 1.6966 - val_loss: 0.6918 - val_mae: 0.6473 - val_mse: 0.6918\n",
      "Epoch 100/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 1.6348 - mae: 0.9273 - mse: 1.6348 - val_loss: 0.7047 - val_mae: 0.6501 - val_mse: 0.7047\n",
      "Epoch 101/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.6153 - mae: 0.9046 - mse: 1.6153 - val_loss: 0.7279 - val_mae: 0.6606 - val_mse: 0.7279\n",
      "Epoch 102/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.1160 - mae: 0.7785 - mse: 1.1160 - val_loss: 0.7150 - val_mae: 0.6541 - val_mse: 0.7150\n",
      "Epoch 103/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.0812 - mae: 0.8176 - mse: 1.0812 - val_loss: 0.8209 - val_mae: 0.6956 - val_mse: 0.8209\n",
      "Epoch 104/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 1.2905 - mae: 0.8512 - mse: 1.2905 - val_loss: 0.6972 - val_mae: 0.6504 - val_mse: 0.6972\n",
      "Epoch 105/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 1.2619 - mae: 0.7922 - mse: 1.2619 - val_loss: 0.6785 - val_mae: 0.6431 - val_mse: 0.6785\n",
      "Epoch 106/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 1.6306 - mae: 0.8997 - mse: 1.6306 - val_loss: 0.7313 - val_mae: 0.6626 - val_mse: 0.7313\n",
      "Epoch 107/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.0559 - mae: 0.7119 - mse: 1.0559 - val_loss: 0.6822 - val_mae: 0.6427 - val_mse: 0.6822\n",
      "Epoch 108/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.0844 - mae: 0.7690 - mse: 1.0844 - val_loss: 0.7534 - val_mae: 0.6710 - val_mse: 0.7534\n",
      "Epoch 109/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 1.2740 - mae: 0.8103 - mse: 1.2740 - val_loss: 0.7758 - val_mae: 0.6788 - val_mse: 0.7758\n",
      "Epoch 110/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 1.2429 - mae: 0.8336 - mse: 1.2429 - val_loss: 0.7136 - val_mae: 0.6535 - val_mse: 0.7136\n",
      "Epoch 111/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 1.1302 - mae: 0.7921 - mse: 1.1302 - val_loss: 0.8170 - val_mae: 0.6934 - val_mse: 0.8170\n",
      "Epoch 112/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 1.5716 - mae: 0.9711 - mse: 1.5716 - val_loss: 0.6839 - val_mae: 0.6410 - val_mse: 0.6839\n",
      "Epoch 113/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.1735 - mae: 0.8085 - mse: 1.1735 - val_loss: 0.6892 - val_mae: 0.6446 - val_mse: 0.6892\n",
      "Epoch 114/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 1.4628 - mae: 0.8442 - mse: 1.4628 - val_loss: 0.6664 - val_mae: 0.6345 - val_mse: 0.6664\n",
      "Epoch 115/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 1.2349 - mae: 0.8316 - mse: 1.2349 - val_loss: 0.6758 - val_mae: 0.6364 - val_mse: 0.6758\n",
      "Epoch 116/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 1.5059 - mae: 0.8487 - mse: 1.5059 - val_loss: 0.6690 - val_mae: 0.6342 - val_mse: 0.6690\n",
      "Epoch 117/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 1.4177 - mae: 0.8296 - mse: 1.4177 - val_loss: 0.7293 - val_mae: 0.6609 - val_mse: 0.7293\n",
      "Epoch 118/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.2727 - mae: 0.8085 - mse: 1.2727 - val_loss: 0.6768 - val_mae: 0.6353 - val_mse: 0.6768\n",
      "Epoch 119/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.9734 - mae: 0.7334 - mse: 0.9734 - val_loss: 0.7196 - val_mae: 0.6564 - val_mse: 0.7196\n",
      "Epoch 120/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 1.2016 - mae: 0.8080 - mse: 1.2016 - val_loss: 0.7138 - val_mae: 0.6538 - val_mse: 0.7138\n",
      "Epoch 121/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 0.8651 - mae: 0.6834 - mse: 0.8651 - val_loss: 0.7137 - val_mae: 0.6535 - val_mse: 0.7137\n",
      "Epoch 122/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 1.3311 - mae: 0.8218 - mse: 1.3311 - val_loss: 0.7331 - val_mae: 0.6618 - val_mse: 0.7331\n",
      "Epoch 123/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.2107 - mae: 0.8181 - mse: 1.2107 - val_loss: 0.7027 - val_mae: 0.6477 - val_mse: 0.7027\n",
      "Epoch 124/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.0420 - mae: 0.7471 - mse: 1.0420 - val_loss: 0.6876 - val_mae: 0.6414 - val_mse: 0.6876\n",
      "Epoch 125/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 1.2030 - mae: 0.8415 - mse: 1.2030 - val_loss: 0.6835 - val_mae: 0.6408 - val_mse: 0.6835\n",
      "Epoch 126/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 1.0086 - mae: 0.7631 - mse: 1.0086 - val_loss: 0.6975 - val_mae: 0.6457 - val_mse: 0.6975\n",
      "Epoch 127/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 1.1539 - mae: 0.7994 - mse: 1.1539 - val_loss: 0.6769 - val_mae: 0.6352 - val_mse: 0.6769\n",
      "Epoch 128/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.4815 - mae: 0.8622 - mse: 1.4815 - val_loss: 0.6963 - val_mae: 0.6438 - val_mse: 0.6963\n",
      "Epoch 129/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 1.0678 - mae: 0.7867 - mse: 1.0678 - val_loss: 0.7267 - val_mae: 0.6589 - val_mse: 0.7267\n",
      "Epoch 130/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 0.9907 - mae: 0.7493 - mse: 0.9907 - val_loss: 0.7438 - val_mae: 0.6651 - val_mse: 0.7438\n",
      "Epoch 131/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 1.6156 - mae: 0.9638 - mse: 1.6156 - val_loss: 0.6949 - val_mae: 0.6431 - val_mse: 0.6949\n",
      "Epoch 132/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 1.0678 - mae: 0.7718 - mse: 1.0678 - val_loss: 0.7129 - val_mae: 0.6521 - val_mse: 0.7129\n",
      "Epoch 133/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 1.1042 - mae: 0.7900 - mse: 1.1042 - val_loss: 0.6951 - val_mae: 0.6438 - val_mse: 0.6951\n",
      "Epoch 134/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 1.4079 - mae: 0.8859 - mse: 1.4079 - val_loss: 0.6743 - val_mae: 0.6328 - val_mse: 0.6743\n",
      "Epoch 135/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 1.0568 - mae: 0.7689 - mse: 1.0568 - val_loss: 0.7017 - val_mae: 0.6459 - val_mse: 0.7017\n",
      "Epoch 136/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 0.9593 - mae: 0.7076 - mse: 0.9593 - val_loss: 0.7131 - val_mae: 0.6517 - val_mse: 0.7131\n",
      "Epoch 137/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 1.0660 - mae: 0.7944 - mse: 1.0660 - val_loss: 0.6992 - val_mae: 0.6442 - val_mse: 0.6992\n",
      "Epoch 138/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 1.3880 - mae: 0.8326 - mse: 1.3880 - val_loss: 0.6806 - val_mae: 0.6350 - val_mse: 0.6806\n",
      "Epoch 139/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.0442 - mae: 0.7675 - mse: 1.0442 - val_loss: 0.7069 - val_mae: 0.6489 - val_mse: 0.7069\n",
      "Epoch 140/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.1667 - mae: 0.8301 - mse: 1.1667 - val_loss: 0.6689 - val_mae: 0.6297 - val_mse: 0.6689\n",
      "Epoch 141/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 1.0932 - mae: 0.7580 - mse: 1.0932 - val_loss: 0.6648 - val_mae: 0.6275 - val_mse: 0.6648\n",
      "Epoch 142/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 1.3037 - mae: 0.8553 - mse: 1.3037 - val_loss: 0.7042 - val_mae: 0.6468 - val_mse: 0.7042\n",
      "Epoch 143/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 1.0983 - mae: 0.7780 - mse: 1.0983 - val_loss: 0.6700 - val_mae: 0.6299 - val_mse: 0.6700\n",
      "Epoch 144/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 1.2906 - mae: 0.8333 - mse: 1.2906 - val_loss: 0.6679 - val_mae: 0.6293 - val_mse: 0.6679\n",
      "Epoch 145/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 1.2367 - mae: 0.8402 - mse: 1.2367 - val_loss: 0.6991 - val_mae: 0.6438 - val_mse: 0.6991\n",
      "Epoch 146/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 1.1969 - mae: 0.8244 - mse: 1.1969 - val_loss: 0.6597 - val_mae: 0.6227 - val_mse: 0.6597\n",
      "Epoch 147/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 1.4690 - mae: 0.8636 - mse: 1.4690 - val_loss: 0.6780 - val_mae: 0.6334 - val_mse: 0.6780\n",
      "Epoch 148/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 1.0939 - mae: 0.7275 - mse: 1.0939 - val_loss: 0.6802 - val_mae: 0.6342 - val_mse: 0.6802\n",
      "Epoch 149/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 1.3562 - mae: 0.8462 - mse: 1.3562 - val_loss: 0.6549 - val_mae: 0.6214 - val_mse: 0.6549\n",
      "Epoch 150/150\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 1.1930 - mae: 0.8336 - mse: 1.1930 - val_loss: 0.6825 - val_mae: 0.6348 - val_mse: 0.6825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x36bc3fa00>"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['mae', 'mse'])\n",
    "model.fit(X_train, y_train, epochs = 150, validation_data = (X_valid, y_valid), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9247 - mae: 0.7305 - mse: 0.9247 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.920026957988739, 0.7223688364028931, 0.920026957988739]"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
